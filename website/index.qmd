---
bibliography: refs.bib
csl: ieee.csl
format:
  html:
    toc: true
    theme:
      light: flatly
      dark: darkly
---

![](header.jpg){width=800}


<div style="text-align: center">


# Implementação de sistema de localização para navegação sem recurso a GNSS 

**Miguel Carrasqueira, Paula Gonçalves, Diogo Silva**

![](fap_afa.png){width=400}

</div>

::: {.callout-note}
Ficheiros de configuração dos algoritmos, parâmetros do piloto automático e desenhos de modulação 3D estão disponíveis, em fonte aberta, em [Github repository](https://github.com/ciafa-sw/Sistema_de_localizacao_SLAM).
:::

Os Unmanned Aircraft System (UAS) têm-se desenvolvido em larga escala, sendo de elevada importância que estes tenham um sistema em que seja possível estimar a sua posição e velocidade. Isto é possível no exterior através de, por exemplo, Global Navigation and Satellite Systems (GNSS). No entanto, nem todos os ambientes têm sinal satélite suficientemente forte, como é o caso do interior de edifícios, ou num cenário onde exista interferência eletromagnética, como, por exemplo, \textit{jamming}. Nestes cenários, os UAS terão de obter a sua localização através de outro tipo de sistemas.
O objetivo primário desta dissertação é o desenvolvimento de um sistema de localização, de modo a ser utilizado na navegação de um UAS de pequenas dimensões em ambientes onde não exista sinal GNSS.
Para o desenvolvimento do sistema de localização foi comparado um Light Detection and Ranging (LIDAR) a uma câmara estereoscópica, sendo posteriormente escolhido o LIDAR como sensor deste sistema. O LIDAR tem o objetivo de capturar a profundidade do ambiente e funciona em conjunto com um algoritmo Simultaneous Localization and Mapping (SLAM) que mapeia o ambiente envolvente e localiza-se no mesmo. Para a comunicação entre estes dois componentes, foi utilizado o Robot Operating System (ROS). Foi feita a integração deste sistema com um piloto automático, de forma a verificar a viabilidade da implementação deste sistema de localização na navegação do UAS.

Este sistema foi testado utilizando dois tipos de abordagens. Inicialmente, realizaram-se testes manuais, com os motores do UAS desligados, para avaliar a precisão do sistema de localização. Posteriormente, foram realizados testes de voo para validar a viabilidade da implementação deste sistema de localização em condições semelhantes às reais.

---

<!-- 
Images from [Seagull dataset](https://vislab.isr.ist.utl.pt/seagull-dataset/) @seagull2017 were used for the test set. These are aerial images of vessels, which represent our target scenario. Our setup was under the assumption that we didn't have enough data for our target scenario. To adress this, we simulated our target scenario with Blender and also used real images from a related domain, i.e. satellite imagery from Airbus Ship Detection Challenge @airbus-ship-detection. We also used GauGAN to produce synthetic images from the related domain. We didn't use generated GauGAN images for the target domain in the training set, as we had very little images and the generated images were fairly similar. 

![Sample of data used for detector training.](img/final_sample.png){width=400}


Our Blender generation process aimed to extend the methodology adopted in the production of the [MarSyn dataset](https://vislab.isr.tecnico.ulisboa.pt/marsyn-dataset/) @marsyn2022, by automating many tasks. 

## Examples from Blender

![Image-segmentation pairs from Blender generated images.](img/blender.png){width=400}




## Examples from GauGAN

![Image-segmentation pairs from GauGAN generated images.](img/gaugan.png){width=400}

-->